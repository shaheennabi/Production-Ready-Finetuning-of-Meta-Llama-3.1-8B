# Understanding Instruction Fine-Tuning

Do you know how large language models are trained and how they generate text like ChatGPT? If not, don't worry! In this document, we will learn about the training of large language models and fine-tuning them on additional data.

Let me take you through it step by step:

First, I hope you are familiar with the **Attention Mechanism**. Back in the days when the **Attention Mechanism** paper hadn't been published, we used neural networks like Recurrent Neural Networks (RNNs), LSTMs, and GRUs, which were good at sequential learning. However, when the **Attention Mechanism** paper was introduced, it gave birth to the Transformer architecture (encoder-decoder). Sequential learning reached new heights because the Transformer was able to focus on specific tokens, making it excellent at predicting the next token and knowing which tokens to focus on.

Similarly, before the advent of large language models, there were some good language models like OpenAI's GPT, BERT (from Google), and T5, which were specialized for specific tasks like text generation, summarization, etc. However, there was no model capable of performing all tasks—like text generation, classification, summarization, translation, and more.

That's when large language models entered the scene. Models like GPT-3 sparked a new revolution in AI, known today as **Generative AI**. These large language models have the ability to generate text, summarize text, translate, and perform many other tasks.

How are these models so effective at these tasks? The answer lies in the fact that these models are trained on massive amounts of **unstructured data**. You heard it right—unstructured data. In the past, when we used models like RNNs and LSTMs, we had to go through multiple stages such as text cleaning, preprocessing, tokenization, and embedding. But large language models are trained on vast amounts of raw, unprocessed data, allowing them to learn a more comprehensive understanding of language.

> **Note:** The base LLM models are trained on unlabelled data, and this process is known as unsupervised learning.

## Working of Large Language Models (LLMs)

Large language models are trained on massive amounts of **unstructured data** that is scraped from the internet, books, encyclopedias, and other sources. These models follow a similar training process to previous architectures, but with the advantage of using the **Transformer architecture**, which excels at focusing attention on specific tokens. As a result, LLMs are highly effective at tasks such as Named Entity Recognition (NER), summarization, and more.

However, there was a time when, despite being trained on such vast datasets, these models were not performing as proficiently as they do today, as seen in systems like ChatGPT.

### What Comes After Training on Massive Unlabelled Data? Fine-Tuning!

## Fine-Tuning

Fine-tuning is not just about providing more information to the LLM. It has specific subtypes, such as **instruction fine-tuning**, which guide the model on how to respond to certain queries or instructions. But, is fine-tuning done in the same way as training the base LLM? The answer is no.

### Supervised Fine-Tuning

In supervised fine-tuning, we don’t train the model on unstructured or unlabelled data. Instead, we fine-tune it on **labelled data**. During the initial training of the base model, the focus was on teaching the model the structure of the language, general understanding of the world, facts, and reasoning capabilities. In fine-tuning, however, we take the base model, which already has a solid understanding, and expose it to **context-specific data** to improve its performance on particular tasks.

For example:
- The model may have general knowledge about cricket.
- If we fine-tune it on cricket-specific data, it will perform better when asked questions about cricket or when asked to generate content related to cricket.

In supervised fine-tuning, we provide the model with labelled data that contains both inputs (such as text or prompts) and the corresponding correct outputs (such as answers or responses). This allows the model to learn the relationship between the input and the expected output.

## Instruction Fine-Tuning

Instruction fine-tuning is a specialized form of fine-tuning that involves training the model to follow specific instructions. This type of fine-tuning helps the model learn how to interpret and respond to certain types of queries or prompts. In instruction fine-tuning, we are teaching the model *how* to behave when asked to perform specific tasks.

For example, instead of just training the model to answer a question (as in traditional supervised fine-tuning), instruction fine-tuning teaches the model how to interpret the task and follow the appropriate steps to generate the correct response.

### Example of Instruction Fine-Tuning for a GPT-like Model:

#### Task: Text Summarization
**Instruction**: "Summarize the following text in one sentence."

**Input**: 
"The sun is a star at the center of our solar system. It is the primary source of energy for life on Earth, and its gravitational pull keeps the planets in orbit around it."

**Output**: 
"The Sun is the central star of our solar system and provides energy for life on Earth while keeping the planets in orbit."

---

#### Task: Sentiment Analysis
**Instruction**: "Determine if the following sentence has a positive or negative sentiment."

**Input**: 
"I absolutely love the new movie I watched yesterday!"

**Output**: 
"Positive"

---

#### Task: Translation
**Instruction**: "Translate the following English sentence into French."

**Input**: 
"Hello, how are you?"

**Output**: 
"Bonjour, comment ça va?"

---

### How Does Instruction Fine-Tuning Work?

1. **Data Preparation**: The data for instruction fine-tuning consists of pairs of instructions and corresponding outputs. The instructions tell the model what task to perform, and the output is the correct response that the model should generate.

2. **Training Objective**: The model learns to follow instructions and generate the correct outputs based on them. The training process typically uses **cross-entropy loss** for tasks like classification or **mean squared error** for regression tasks, where the model's predicted output is compared to the ground truth.

3. **Example Tasks**: Tasks can include question answering, text generation, summarization, translation, sentiment analysis, and many others.

### Example Instruction Fine-Tuning Prompts

Here’s a deeper dive into the application of instruction fine-tuning with more examples:

- **Task: Text Summarization**
  - **Instruction**: "Summarize the following text in one sentence."
  - **Input**: "The sun is a star at the center of our solar system. It is the primary source of energy for life on Earth, and its gravitational pull keeps the planets in orbit around it."
  - **Output**: "The Sun is the central star of our solar system and provides energy for life on Earth while keeping the planets in orbit."

- **Task: Sentiment Analysis**
  - **Instruction**: "Determine if the following sentence has a positive or negative sentiment."
  - **Input**: "I absolutely love the new movie I watched yesterday!"
  - **Output**: "Positive"

- **Task: Translation**
  - **Instruction**: "Translate the following English sentence into French."
  - **Input**: "Hello, how are you?"
  - **Output**: "Bonjour, comment ça va?"

---

### Conclusion

Instruction fine-tuning is a crucial technique for enhancing large language models by teaching them how to interpret and respond to specific types of instructions. By training models on carefully designed pairs of instructions and expected outputs, we can improve their performance on a wide range of tasks, from summarization to sentiment analysis to translation. This allows us to build models that are not only good at generating text but also highly skilled at understanding and following complex instructions.

_Caution_: This document was written by me, with some improvements from ChatGPT. The concepts are presented in an easy-to-understand manner with the hope that you find them useful.
